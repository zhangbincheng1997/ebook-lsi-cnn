{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载语料\n",
    "这个压缩包里面存的是标题、正文部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取正文\n",
    "将 xml 格式的 wiki 数据转换为 text 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "from gensim.corpora import WikiCorpus\n",
    "\n",
    "input = \"./zhwiki-latest-pages-articles.xml.bz2\"\n",
    "output = './wiki.zh.text'\n",
    "with open(output, 'w') as f:\n",
    "    wiki =  WikiCorpus(input, lemmatize=False, dictionary={})\n",
    "    for text in wiki.get_texts():\n",
    "        str_line = ' '.join(text)\n",
    "        f.write(str_line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繁简转换\n",
    "如果抽取中文的话需要将繁体转化为简体(维基百科的中文数据是繁简混杂的，里面包含大陆简体、台湾繁体、港澳繁体等多种不同的数据)。可以使用opencc进行转换，也可以使用其它繁简转换工具。\n",
    "```\n",
    "Options:\n",
    " -i [file], --input=[file]   Read original text from [file].\n",
    " -o [file], --output=[file]  Write converted text to [file].\n",
    " -c [file], --config=[file]  Load configuration of conversion from [file].\n",
    " -v, --version               Print version and build information.\n",
    " -h, --help                  Print this help.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!opencc -i wiki.zh.text -o wiki.zh.text.jian -c zht2zhs.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码转换\n",
    "由于后续的分词需要使用utf-8格式的字符，而上述简体字中可能存在非utf-8的字符集，避免在分词时候进行到一半而出现错误，因此先进行字符格式转换。 \n",
    "\n",
    "使用iconv命令将文件转换成utf-8编码。\n",
    "```\n",
    " 输入/输出格式规范：\n",
    "  -f, --from-code=名称     原始文本编码\n",
    "  -t, --to-code=名称       输出编码\n",
    "\n",
    " 信息：\n",
    "  -l, --list                 列举所有已知的字符集\n",
    "\n",
    " 输出控制：\n",
    "  -c                         从输出中忽略无效的字符\n",
    "  -o, --output=文件        输出文件\n",
    "  -s, --silent               关闭警告\n",
    "      --verbose              打印进度信息\n",
    "\n",
    "  -?, --help                 给出该系统求助列表\n",
    "      --usage                给出简要的用法信息\n",
    "  -V, --version              打印程序版本号\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!iconv -c -t UTF-8 wiki.zh.text.jian > wiki.zh.text.jian.utf8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jieba\n",
    "!python -m jieba -d ' ' wiki.zh.text.jian.utf8 > wiki.zh.text.jian.utf8.seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import logging\n",
    "\n",
    "input = './wiki.zh.text.jian.utf8.seg'\n",
    "output = './wiki.vector'\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = word2vec.LineSentence(input)\n",
    "model = word2vec.Word2Vec(sentences, size=100, window=5, min_count=5, workers=4)\n",
    "model.wv.save_word2vec_format(output, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('./wiki.vector', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7293198108673096),\n",
       " ('bride', 0.683803915977478),\n",
       " ('mistress', 0.6707652807235718),\n",
       " ('prince', 0.6648019552230835),\n",
       " ('wives', 0.6588137149810791),\n",
       " ('princess', 0.6529775857925415),\n",
       " ('queens', 0.6459839344024658),\n",
       " ('daughters', 0.6443694829940796),\n",
       " ('mother', 0.6377485990524292),\n",
       " ('godmother', 0.6289682388305664)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model['女人'] + model['国王'] - model['男人'] = model['皇后']\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6361447854063201"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6681771014772736"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('queen', 'king')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
